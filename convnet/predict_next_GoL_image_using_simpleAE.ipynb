{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "import chainer\n",
    "from chainer.dataset import convert\n",
    "import cv2\n",
    "import net_conv\n",
    "import hickle as hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data input-output variables\n",
    "# path to dataset hkl files\n",
    "PATH = '../datasets/gol/'\n",
    "PATH_glider = '../datasets/glider/'\n",
    "# output path\n",
    "out = 'results/gol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training, validation and test data\n",
    "X_train = hkl.load(PATH + 'X_train.hkl')\n",
    "X_train = X_train / 255.\n",
    "X_train = X_train.astype('float32')\n",
    "#?sources = hkl.load(PATH + 'sources_train.hkl')\n",
    "\n",
    "X_val = hkl.load(PATH + 'X_val.hkl')\n",
    "X_val = X_val / 255.\n",
    "X_val = X_val.astype('float32')\n",
    "#?sources_val = hkl.load(PATH + 'sources_val.hkl')\n",
    "\n",
    "X_test = hkl.load(PATH + 'X_test.hkl')\n",
    "X_test = X_test / 255.\n",
    "X_test = X_test.astype('float32')\n",
    "#?sources_test = hkl.load(PATH + 'sources_test.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb26141fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of input data\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_0 = X_train[0].shape[0]\n",
    "input_size_1 = X_train[0].shape[1]\n",
    "gpu = -1\n",
    "dimz = 10\n",
    "batchsize = 16\n",
    "epoch = 100\n",
    "initmodel = ''\n",
    "resume = ''\n",
    "is_test = False #'store_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: -1\n",
      "# dim z: 10\n",
      "# Minibatch-size: 16\n",
      "# epoch: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GPU: {}'.format(gpu))\n",
    "print('# dim z: {}'.format(dimz))\n",
    "print('# Minibatch-size: {}'.format(batchsize))\n",
    "print('# epoch: {}'.format(epoch))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize / Resume\n",
    "if initmodel:\n",
    "    chainer.serializers.load_npz(initmodel, model)\n",
    "if resume:\n",
    "    chainer.serializers.load_npz(resume, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data list\n",
    "train = list()\n",
    "for idx in range(len(X_train)-1):\n",
    "    if sources[idx] == sources[idx+1]:\n",
    "        train.append((np.transpose(X_train[idx], (2,0,1)), np.transpose(X_train[idx+1], (2,0,1))))\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation data list\n",
    "val = list()\n",
    "for idx in range(len(X_val)-1):\n",
    "    if sources2[idx] == sources2[idx+1]:\n",
    "        val.append((np.transpose(X_val[idx], (2,0,1)), np.transpose(X_val[idx+1], (2,0,1))))\n",
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data list\n",
    "test = list()\n",
    "for idx in range(len(X_test)):\n",
    "    test.append(np.transpose(X_test[idx], (2,0,1)))\n",
    "test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train)\n",
    "random.shuffle(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    train, _ = chainer.datasets.split_dataset(train, 100)\n",
    "    val, _ = chainer.datasets.split_dataset(val, 100)\n",
    "train_count = len(train)\n",
    "val_count = len(val)\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "val_iter = chainer.iterators.SerialIterator(val, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.adam.Adam at 0xb275683c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net_conv.ConvAE_mini(input_size_0=input_size_0, input_size_1=input_size_1, channel_size=3, n_filters=10, n_latent=dimz, filter_size=3, activation='relu')\n",
    "# Setup an optimizer\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train mean loss=519.4925\n",
      "test mean loss=29718.782248263888\n",
      "2\n",
      "train mean loss=259.1504861111111\n",
      "test mean loss=14399.568684895834\n",
      "3\n",
      "train mean loss=130.03690972222222\n",
      "test mean loss=7526.9036241319445\n",
      "4\n",
      "train mean loss=99.30638888888889\n",
      "test mean loss=5504.902571614583\n",
      "5\n",
      "train mean loss=82.37760416666667\n",
      "test mean loss=4778.95458984375\n",
      "6\n",
      "train mean loss=81.05361111111111\n",
      "test mean loss=4439.381472439236\n",
      "7\n",
      "train mean loss=70.81510416666667\n",
      "test mean loss=4231.436100260416\n",
      "8\n",
      "train mean loss=69.66587239583333\n",
      "test mean loss=4094.926736111111\n",
      "9\n",
      "train mean loss=68.83686631944444\n",
      "test mean loss=3993.2061577690974\n",
      "10\n",
      "train mean loss=64.25390190972222\n",
      "test mean loss=3917.165261501736\n",
      "11\n",
      "train mean loss=66.50163628472222\n",
      "test mean loss=3866.642377387153\n",
      "12\n",
      "train mean loss=89.76614583333334\n",
      "test mean loss=3826.6127983940974\n",
      "13\n",
      "train mean loss=65.7190234375\n",
      "test mean loss=3792.4627332899304\n",
      "14\n",
      "train mean loss=58.578815104166665\n",
      "test mean loss=3763.8424207899307\n",
      "15\n",
      "train mean loss=67.40148003472223\n",
      "test mean loss=3741.2982530381946\n",
      "16\n",
      "train mean loss=66.36851128472222\n",
      "test mean loss=3722.1893391927083\n",
      "17\n",
      "train mean loss=53.49005208333333\n",
      "test mean loss=3704.4796495225696\n",
      "18\n",
      "train mean loss=56.83572916666667\n",
      "test mean loss=3689.0147081163195\n",
      "19\n",
      "train mean loss=65.42580295138889\n",
      "test mean loss=3673.915706380208\n",
      "20\n",
      "train mean loss=63.77600260416666\n",
      "test mean loss=3659.251388888889\n",
      "21\n",
      "train mean loss=72.09531684027777\n",
      "test mean loss=3644.0499131944443\n",
      "22\n",
      "train mean loss=58.999583333333334\n",
      "test mean loss=3629.5552897135417\n",
      "23\n",
      "train mean loss=61.37853298611111\n",
      "test mean loss=3615.2247124565974\n",
      "24\n",
      "train mean loss=71.44936197916667\n",
      "test mean loss=3600.4117241753474\n",
      "25\n",
      "train mean loss=52.09631076388889\n",
      "test mean loss=3584.6333604600695\n",
      "26\n",
      "train mean loss=56.325703125\n",
      "test mean loss=3562.2407280815974\n",
      "27\n",
      "train mean loss=61.668268229166664\n",
      "test mean loss=3541.657297092014\n",
      "28\n",
      "train mean loss=59.826137152777775\n",
      "test mean loss=3523.4629177517363\n",
      "29\n",
      "train mean loss=60.738719618055555\n",
      "test mean loss=3505.1475531684027\n",
      "30\n",
      "train mean loss=52.97219618055556\n",
      "test mean loss=3487.333566623264\n",
      "31\n",
      "train mean loss=59.82644097222222\n",
      "test mean loss=3469.153759765625\n",
      "32\n",
      "train mean loss=52.86704427083333\n",
      "test mean loss=3449.434152560764\n",
      "33\n",
      "train mean loss=58.58756076388889\n",
      "test mean loss=3428.361083984375\n",
      "34\n",
      "train mean loss=60.307200520833334\n",
      "test mean loss=3406.3631510416667\n",
      "35\n",
      "train mean loss=56.6487890625\n",
      "test mean loss=3383.4949652777777\n",
      "36\n",
      "train mean loss=65.25040364583333\n",
      "test mean loss=3358.671088324653\n",
      "37\n",
      "train mean loss=56.118389756944445\n",
      "test mean loss=3331.4217881944446\n",
      "38\n",
      "train mean loss=63.74333333333333\n",
      "test mean loss=3304.5317654079863\n",
      "39\n",
      "train mean loss=54.05344184027778\n",
      "test mean loss=3273.6917914496526\n",
      "40\n",
      "train mean loss=51.65197048611111\n",
      "test mean loss=3239.608203125\n",
      "41\n",
      "train mean loss=56.73911892361111\n",
      "test mean loss=3204.279709201389\n",
      "42\n",
      "train mean loss=53.25832899305556\n",
      "test mean loss=3169.304931640625\n",
      "43\n",
      "train mean loss=53.8071484375\n",
      "test mean loss=3132.69208984375\n",
      "44\n",
      "train mean loss=56.03766059027778\n",
      "test mean loss=3095.380072699653\n",
      "45\n",
      "train mean loss=50.17310329861111\n",
      "test mean loss=3055.9662489149305\n",
      "46\n",
      "train mean loss=49.20813802083333\n",
      "test mean loss=3016.776177300347\n",
      "47\n",
      "train mean loss=52.244053819444446\n",
      "test mean loss=2977.934380425347\n",
      "48\n",
      "train mean loss=51.70816840277778\n",
      "test mean loss=2939.348356119792\n",
      "49\n",
      "train mean loss=50.21072916666667\n",
      "test mean loss=2895.005322265625\n",
      "50\n",
      "train mean loss=47.68256510416666\n",
      "test mean loss=2851.6597819010417\n",
      "51\n",
      "train mean loss=48.22113715277778\n",
      "test mean loss=2809.606146918403\n",
      "52\n",
      "train mean loss=50.69112413194444\n",
      "test mean loss=2767.860183376736\n",
      "53\n",
      "train mean loss=43.33535590277778\n",
      "test mean loss=2724.0683322482637\n",
      "54\n",
      "train mean loss=45.692057291666664\n",
      "test mean loss=2679.2982476128473\n",
      "55\n",
      "train mean loss=45.20634548611111\n",
      "test mean loss=2616.3094563802083\n",
      "56\n",
      "train mean loss=42.09649739583333\n",
      "test mean loss=2563.7229112413193\n",
      "57\n",
      "train mean loss=44.81936631944444\n",
      "test mean loss=2512.0179144965277\n",
      "58\n",
      "train mean loss=40.421184895833335\n",
      "test mean loss=2462.289914279514\n",
      "59\n",
      "train mean loss=40.73015625\n",
      "test mean loss=2416.89248046875\n",
      "60\n",
      "train mean loss=38.02071614583333\n",
      "test mean loss=2374.9863009982637\n",
      "61\n",
      "train mean loss=38.860881076388885\n",
      "test mean loss=2333.632695855035\n",
      "62\n",
      "train mean loss=41.7015625\n",
      "test mean loss=2293.7121880425348\n",
      "63\n",
      "train mean loss=37.18281684027778\n",
      "test mean loss=2255.1985134548613\n",
      "64\n",
      "train mean loss=42.71111979166667\n",
      "test mean loss=2218.6208116319444\n",
      "65\n",
      "train mean loss=39.326710069444445\n",
      "test mean loss=2181.5529730902776\n",
      "66\n",
      "train mean loss=34.01906684027778\n",
      "test mean loss=2146.485959201389\n",
      "67\n",
      "train mean loss=37.92083767361111\n",
      "test mean loss=2111.4762722439236\n",
      "68\n",
      "train mean loss=37.302235243055556\n",
      "test mean loss=2076.7837809244793\n",
      "69\n",
      "train mean loss=33.69114583333333\n",
      "test mean loss=2042.9439968532986\n",
      "70\n",
      "train mean loss=31.820911458333335\n",
      "test mean loss=2010.1891845703126\n",
      "71\n",
      "train mean loss=33.34361328125\n",
      "test mean loss=1977.79697265625\n",
      "72\n",
      "train mean loss=36.14771484375\n",
      "test mean loss=1945.4203450520833\n",
      "73\n",
      "train mean loss=34.82531032986111\n",
      "test mean loss=1913.900062391493\n",
      "74\n",
      "train mean loss=31.383059895833334\n",
      "test mean loss=1882.578724500868\n",
      "75\n",
      "train mean loss=34.31718967013889\n",
      "test mean loss=1851.3239637586805\n",
      "76\n",
      "train mean loss=31.617026909722224\n",
      "test mean loss=1820.9120686848958\n",
      "77\n",
      "train mean loss=29.1965625\n",
      "test mean loss=1789.0889675564235\n",
      "78\n",
      "train mean loss=30.058780381944445\n",
      "test mean loss=1747.3354193793402\n",
      "79\n",
      "train mean loss=30.275983072916667\n",
      "test mean loss=1709.2473958333333\n",
      "80\n",
      "train mean loss=27.073253038194444\n",
      "test mean loss=1675.090177408854\n",
      "81\n",
      "train mean loss=30.025145399305554\n",
      "test mean loss=1642.160706922743\n",
      "82\n",
      "train mean loss=28.825885416666665\n",
      "test mean loss=1610.5475775824652\n",
      "83\n",
      "train mean loss=26.20029079861111\n",
      "test mean loss=1579.530783420139\n",
      "84\n",
      "train mean loss=26.234368489583332\n",
      "test mean loss=1547.844637044271\n",
      "85\n",
      "train mean loss=24.600970052083333\n",
      "test mean loss=1515.711048719618\n",
      "86\n",
      "train mean loss=25.18426432291667\n",
      "test mean loss=1486.5060356987847\n",
      "87\n",
      "train mean loss=23.118721788194446\n",
      "test mean loss=1457.8691324869792\n",
      "88\n",
      "train mean loss=24.225080295138888\n",
      "test mean loss=1430.0058295355902\n",
      "89\n",
      "train mean loss=22.980785590277776\n",
      "test mean loss=1400.9015028211807\n",
      "90\n",
      "train mean loss=24.186671006944444\n",
      "test mean loss=1368.4172878689237\n",
      "91\n",
      "train mean loss=23.639346788194445\n",
      "test mean loss=1339.0036159939236\n",
      "92\n",
      "train mean loss=21.1183203125\n",
      "test mean loss=1311.6329264322917\n",
      "93\n",
      "train mean loss=22.10712890625\n",
      "test mean loss=1282.737703450521\n",
      "94\n",
      "train mean loss=21.400082465277777\n",
      "test mean loss=1256.872531467014\n",
      "95\n",
      "train mean loss=19.452235243055554\n",
      "test mean loss=1231.5414496527778\n",
      "96\n",
      "train mean loss=22.974680989583334\n",
      "test mean loss=1206.648228624132\n",
      "97\n",
      "train mean loss=19.467443576388888\n",
      "test mean loss=1182.7214545355903\n",
      "98\n",
      "train mean loss=20.82484809027778\n",
      "test mean loss=1160.820347764757\n",
      "99\n",
      "train mean loss=18.35529079861111\n",
      "test mean loss=1139.973055013021\n",
      "100\n",
      "train mean loss=18.35701388888889\n",
      "test mean loss=1119.8712727864583\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "while train_iter.epoch < epoch:\n",
    "    sum_loss = 0\n",
    "    batch = train_iter.next()\n",
    "    x_array_0 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "    x_array_1 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "    x = chainer.Variable(x_array_0)\n",
    "    # Update model based on the loss function\n",
    "    # defined by model.get_loss_func()\n",
    "    optimizer.update(model.get_loss_func(), x, x_array_1)\n",
    "    sum_loss += float(model.loss.data) * len(x.data)\n",
    "    if train_iter.is_new_epoch:\n",
    "        print(c)\n",
    "        c += 1\n",
    "        print('train mean loss={}'.format(sum_loss / train_count))\n",
    "        # evaluation\n",
    "        sum_loss = 0\n",
    "        for batch in val_iter:\n",
    "            x_array_0 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "            x_array_1 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "            x = chainer.Variable(x_array_0)\n",
    "            loss_func = model.get_loss_func(k=10)\n",
    "            loss_func(x, x_array_1)\n",
    "            sum_loss += float(model.loss.data) * len(x.data)\n",
    "        val_iter.reset()\n",
    "        print('val mean loss={}'.format(sum_loss / val_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model\n",
      "save the optimizer\n"
     ]
    }
   ],
   "source": [
    "# Save the model and the optimizer\n",
    "# Check if folder exist \n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "print('save the model')\n",
    "chainer.serializers.save_npz(os.path.join(out, 'model.model'), model)\n",
    "print('save the optimizer')\n",
    "chainer.serializers.save_npz(os.path.join(out, 'state.state'), optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def save_images(x, filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(9, 9), dpi=100)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi[0])\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "plt.gray()\n",
    "model.to_cpu()\n",
    "train_ind = np.random.randint(0,len(train),9)\n",
    "# train_ind = [0,1,2,3,4,5,6,7,8]\n",
    "batch = np.asarray(train)[train_ind]\n",
    "x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "x = chainer.Variable(x_array1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)\n",
    "save_images(x_array1, os.path.join(out, 'train_x'))\n",
    "save_images(x_array2, os.path.join(out, 'train_xnext'))\n",
    "save_images(x1.data, os.path.join(out, 'train_xnextreconstructed'))\n",
    "\n",
    "# test_ind = np.random.randint(0,len(test),9)\n",
    "test_ind = [0,1,2,3,4,5,6,7,8]\n",
    "batch = np.asarray(test)[test_ind]\n",
    "x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "x = chainer.Variable(x_array1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)\n",
    "save_images(x_array1, os.path.join(out, 'test_x'))\n",
    "save_images(x_array2, os.path.join(out, 'test_xnext'))\n",
    "save_images(x1.data, os.path.join(out, 'test_xnextreconstructed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can this model predict a Glider?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_g = hkl.load(PATH_glider + 'X_test.hkl')\n",
    "X_test_g = X_test_g / 255.\n",
    "X_test_g = X_test_g.astype('float32')\n",
    "sources_test_g = hkl.load(PATH_glider + 'sources_test.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of input data\n",
    "plt.imshow(X_test_g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict glider data\n",
    "glider = list()\n",
    "for idx in range(len(X_test_g)-1):\n",
    "    if sources_test_g[idx] == sources_test_g[idx+1]:\n",
    "        glider.append((np.transpose(X_test_g[idx], (2,0,1)), np.transpose(X_test_g[idx+1], (2,0,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def save_images2(x, filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(5, 5, figsize=(9, 9), dpi=100)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi[0])\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "glider_ind = range(25)#[0,1,2,3,4,5,6,7,8]\n",
    "batch = np.asarray(glider)[glider_ind]\n",
    "x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "x = chainer.Variable(x_array1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)\n",
    "save_images2(x_array1, os.path.join(out, 'glider_x'))\n",
    "save_images2(x_array2, os.path.join(out, 'glider_xnext'))\n",
    "save_images2(x1.data, os.path.join(out, 'glider_xnextreconstructed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for paper (same format as Prednet output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ind = [0,1,2,3,4,5,6,7,8,9]\n",
    "test_ind = list(np.linspace(0, 99, 100, dtype='int32'))\n",
    "batch = np.asarray(test_for_plot)[test_ind]\n",
    "# test_ind = list(np.linspace(0, 9, 10, dtype='int32'))\n",
    "# batch = np.asarray(test_for_plot_glider)[test_ind]\n",
    "x_array_1 = convert.concat_examples(list(map(lambda x: x, batch)), gpu)\n",
    "x = chainer.Variable(x_array_1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array_1.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_array_1.transpose(0,2,3,1).reshape(int(x_array1.data.shape[0]/10), 10, input_shape_0, input_shape_1, 3)\n",
    "X_hat = x1.data.transpose(0,2,3,1).reshape(int(input_shape_0.data.shape[0]/10), 10, input_shape_0, input_shape_1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.gray()\n",
    "nt = 10\n",
    "aspect_ratio = 0.8\n",
    "# plt.figure(figsize = (nt, 2*aspect_ratio))\n",
    "plt.figure(figsize = (100/7.2, 16/7.2))\n",
    "gs = gridspec.GridSpec(2, nt)\n",
    "gs.update(wspace=0., hspace=0.)\n",
    "plot_save_dir = 'fig_for_paper/gol_large/'\n",
    "if not os.path.exists(plot_save_dir): os.mkdir(plot_save_dir)\n",
    "plot_idx = np.random.permutation(X_test.shape[0])\n",
    "\n",
    "for i in plot_idx:\n",
    "    for t in range(nt):     \n",
    "        plt.subplot(gs[t])\n",
    "        plt.imshow(X_test[i,t], interpolation='none')\n",
    "        plt.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "        if t==0: plt.ylabel('Actual', fontsize=10)\n",
    "\n",
    "        plt.subplot(gs[t + nt])\n",
    "        if t % 10 == 0:\n",
    "            plt.imshow(np.zeros(X_hat[0,0].shape), interpolation='none')\n",
    "        else:\n",
    "            plt.imshow(X_hat[i,t-1], interpolation='none')\n",
    "        plt.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "        if t==0: plt.ylabel('Predicted', fontsize=10)\n",
    "    \n",
    "    plt.savefig(plot_save_dir +  'plot_' + str(i) + '.png')\n",
    "    plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = 0\n",
    "mse_prev = 0\n",
    "c = 0\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[0])-1):\n",
    "        mse_model += np.mean((X_test[i,j+1,:,:] - X_hat[i,j,:,:])**2)\n",
    "        mse_prev += np.mean((X_test[i,j+1,:,:] - X_test[i,j,:,:])**2)        \n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_prev/c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
