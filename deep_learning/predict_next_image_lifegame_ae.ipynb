{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "import chainer\n",
    "from chainer.dataset import convert\n",
    "import cv2\n",
    "import net_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lifegame_data.pickle', 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "\n",
    "d[0] = np.array(list(map(lambda x: x.astype('float32'), d[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "\n",
    "plt.imshow(d[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = d[0][0].shape[0]\n",
    "gpu = -1\n",
    "dimz = 20\n",
    "batchsize = 32\n",
    "epoch = 20\n",
    "initmodel = ''\n",
    "resume = ''\n",
    "out = 'result'\n",
    "is_test = False #'store_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GPU: {}'.format(gpu))\n",
    "print('# dim z: {}'.format(dimz))\n",
    "print('# Minibatch-size: {}'.format(batchsize))\n",
    "print('# epoch: {}'.format(epoch))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize / Resume\n",
    "if initmodel:\n",
    "    chainer.serializers.load_npz(initmodel, model)\n",
    "if resume:\n",
    "    chainer.serializers.load_npz(resume, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list()\n",
    "for i in range(len(d[0])-1):\n",
    "#     idx = i % 100\n",
    "    idx = i\n",
    "    if d[1][idx] == False:\n",
    "        train.append((d[0][idx].reshape(1, N, N), d[0][idx+1].reshape(1, N, N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80000\n",
    "test = train[n:]\n",
    "train = train[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    train, _ = chainer.datasets.split_dataset(train, 100)\n",
    "    test, _ = chainer.datasets.split_dataset(test, 100)\n",
    "train_count = len(train)\n",
    "test_count = len(test)\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net_conv.ConvAE_mini(input_size=N, n_filters=20, n_latent=dimz, filter_size=3, activation='relu')\n",
    "# Setup an optimizer\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 1\n",
    "while train_iter.epoch < epoch:\n",
    "    sum_loss = 0\n",
    "    batch = train_iter.next()\n",
    "    x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "    x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "    x = chainer.Variable(x_array1)\n",
    "    # Update model based on the loss function\n",
    "    # defined by model.get_loss_func()\n",
    "    optimizer.update(model.get_loss_func(), x, x_array2)\n",
    "    sum_loss += float(model.loss.data) * len(x.data)\n",
    "    if train_iter.is_new_epoch:\n",
    "        print(c)\n",
    "        c += 1\n",
    "        print('train mean loss={}'.format(sum_loss / train_count))\n",
    "        # evaluation\n",
    "        sum_loss = 0\n",
    "        for batch in test_iter:\n",
    "            x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "            x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "            x = chainer.Variable(x_array1)\n",
    "            loss_func = model.get_loss_func(k=10)\n",
    "            loss_func(x, x_array2)\n",
    "            sum_loss += float(model.loss.data) * len(x.data)\n",
    "        test_iter.reset()\n",
    "        print('test mean loss={}'.format(sum_loss / test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that os.makedirs(path, exist_ok=True) can be used\n",
    "# if this script only supports python3\n",
    "if not os.path.exists(out):\n",
    "    os.mkdir(out)\n",
    "\n",
    "# Save the model and the optimizer\n",
    "print('save the model')\n",
    "chainer.serializers.save_npz(os.path.join(out, 'model-1.model'), model)\n",
    "print('save the optimizer')\n",
    "chainer.serializers.save_npz(os.path.join(out, 'state-1.state'), optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def save_images(x, filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(9, 9), dpi=100)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi[0])\n",
    "    fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to_cpu()\n",
    "train_ind = np.random.randint(0,len(train),9)\n",
    "# train_ind = [0,1,2,3,4,5,6,7,8]\n",
    "batch = np.asarray(train)[train_ind]\n",
    "x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "x = chainer.Variable(x_array1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)\n",
    "save_images(x_array1, os.path.join(out, 'train_x'))\n",
    "save_images(x_array2, os.path.join(out, 'train_xnext'))\n",
    "save_images(x1.data, os.path.join(out, 'train_xnextreconstructed'))\n",
    "\n",
    "test_ind = np.random.randint(0,len(test),9)\n",
    "batch = np.asarray(test)[test_ind]\n",
    "x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "x = chainer.Variable(x_array1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)\n",
    "save_images(x_array1, os.path.join(out, 'test_x'))\n",
    "save_images(x_array2, os.path.join(out, 'test_xnext'))\n",
    "save_images(x1.data, os.path.join(out, 'test_xnextreconstructed'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can this model predict Glider? or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lifegame_data_glider.pickle', 'rb') as f:\n",
    "    d2 = pickle.load(f)\n",
    "\n",
    "d2[0] = np.array(list(map(lambda x: x.astype('float32'), d2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "plt.imshow(d2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glider = list()\n",
    "for i in range(len(d2[0])-1):\n",
    "    idx = i\n",
    "    if d2[1][idx] == False:\n",
    "        glider.append((d2[0][idx].reshape(1, N, N), d2[0][idx+1].reshape(1, N, N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def save_images2(x, filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(5, 5, figsize=(9, 9), dpi=100)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi[0])\n",
    "    fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glider_ind = range(25)#[0,1,2,3,4,5,6,7,8]\n",
    "batch = np.asarray(glider)[glider_ind]\n",
    "x_array1 = convert.concat_examples(list(map(lambda x: x[0], batch)), gpu)\n",
    "x_array2 = convert.concat_examples(list(map(lambda x: x[1], batch)), gpu)\n",
    "x = chainer.Variable(x_array1)\n",
    "with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "    x1 = model(x)\n",
    "save_images2(x_array1, os.path.join(out, 'glider_x'))\n",
    "save_images2(x_array2, os.path.join(out, 'glider_xnext'))\n",
    "save_images2(x1.data, os.path.join(out, 'glider_xnextreconstructed'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
